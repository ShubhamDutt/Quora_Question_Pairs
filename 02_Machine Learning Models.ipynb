{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dd1ecae",
   "metadata": {},
   "source": [
    "# 4. Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a629b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine # database connection\n",
    "import csv\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import math\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_curve, auc, roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337f0a33",
   "metadata": {},
   "source": [
    "## 4.1 Reading data from file and storing into SQL table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32c6a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DB file from CSV\n",
    "\n",
    "if not os.path.isfile('train.db'):\n",
    "    disk_engine = create_engine('sqlite:///train.db')\n",
    "    start = dt.datetime.now()\n",
    "    chunksize = 180000\n",
    "    j = 0\n",
    "    index_start = 1\n",
    "    for data in pd.read_csv('final_features.csv', names=['Unnamed: 0','id','is_duplicate','cwc_min','cwc_max','csc_min','csc_max','ctc_min','ctc_max','last_word_eq','first_word_eq','abs_len_diff','mean_len','token_set_ratio','token_sort_ratio','fuzz_ratio','fuzz_partial_ratio','longest_substr_ratio','freq_qid1','freq_qid2','q1len','q2len','q1_n_words','q2_n_words','word_Common','word_Total','word_share','freq_q1+q2','freq_q1-q2',\n",
    "                                                       '0_x','1_x','2_x','3_x','4_x','5_x','6_x','7_x','8_x','9_x','10_x','11_x','12_x','13_x','14_x','15_x','16_x','17_x','18_x','19_x','20_x','21_x','22_x','23_x','24_x','25_x','26_x','27_x','28_x','29_x','30_x','31_x','32_x','33_x','34_x','35_x','36_x','37_x','38_x','39_x','40_x','41_x','42_x','43_x','44_x','45_x','46_x','47_x','48_x','49_x','50_x','51_x','52_x','53_x','54_x',\n",
    "                                                       '55_x','56_x','57_x','58_x','59_x','60_x','61_x','62_x','63_x','64_x','65_x','66_x','67_x','68_x','69_x','70_x','71_x','72_x','73_x','74_x','75_x','76_x','77_x','78_x','79_x','80_x','81_x','82_x','83_x','84_x','85_x','86_x','87_x','88_x','89_x','90_x','91_x','92_x','93_x','94_x','95_x','96_x','97_x','98_x','99_x','100_x','101_x','102_x','103_x','104_x','105_x','106_x','107_x',\n",
    "                                                       '108_x','109_x','110_x','111_x','112_x','113_x','114_x','115_x','116_x','117_x','118_x','119_x','120_x','121_x','122_x','123_x','124_x','125_x','126_x','127_x','128_x','129_x','130_x','131_x','132_x','133_x','134_x','135_x','136_x','137_x','138_x','139_x','140_x','141_x','142_x','143_x','144_x','145_x','146_x','147_x','148_x','149_x','150_x','151_x','152_x','153_x','154_x',\n",
    "                                                       '155_x','156_x','157_x','158_x','159_x','160_x','161_x','162_x','163_x','164_x','165_x','166_x','167_x','168_x','169_x','170_x','171_x','172_x','173_x','174_x','175_x','176_x','177_x','178_x','179_x','180_x','181_x','182_x','183_x','184_x','185_x','186_x','187_x','188_x','189_x','190_x','191_x','192_x','193_x','194_x','195_x','196_x','197_x','198_x','199_x','200_x','201_x',\n",
    "                                                       '202_x','203_x','204_x','205_x','206_x','207_x','208_x','209_x','210_x','211_x','212_x','213_x','214_x','215_x','216_x','217_x','218_x','219_x','220_x','221_x','222_x','223_x','224_x','225_x','226_x','227_x','228_x','229_x','230_x','231_x','232_x','233_x','234_x','235_x','236_x','237_x','238_x','239_x','240_x','241_x','242_x','243_x','244_x','245_x','246_x','247_x','248_x',\n",
    "                                                       '249_x','250_x','251_x','252_x','253_x','254_x','255_x','256_x','257_x','258_x','259_x','260_x','261_x','262_x','263_x','264_x','265_x','266_x','267_x','268_x','269_x','270_x','271_x','272_x','273_x','274_x','275_x','276_x','277_x','278_x','279_x','280_x','281_x','282_x','283_x','284_x','285_x','286_x','287_x','288_x','289_x','290_x','291_x','292_x','293_x','294_x','295_x',\n",
    "                                                       '296_x','297_x','298_x','299_x','300_x','301_x','302_x','303_x','304_x','305_x','306_x','307_x','308_x','309_x','310_x','311_x','312_x','313_x','314_x','315_x','316_x','317_x','318_x','319_x','320_x','321_x','322_x','323_x','324_x','325_x','326_x','327_x','328_x','329_x','330_x','331_x','332_x','333_x','334_x','335_x','336_x','337_x','338_x','339_x','340_x','341_x','342_x',\n",
    "                                                       '343_x','344_x','345_x','346_x','347_x','348_x','349_x','350_x','351_x','352_x','353_x','354_x','355_x','356_x','357_x','358_x','359_x','360_x','361_x','362_x','363_x','364_x','365_x','366_x','367_x','368_x','369_x','370_x','371_x','372_x','373_x','374_x','375_x','376_x','377_x','378_x','379_x','380_x','381_x','382_x','383_x',\n",
    "                                                       '0_y','1_y','2_y','3_y','4_y','5_y','6_y','7_y','8_y','9_y','10_y','11_y','12_y','13_y','14_y','15_y','16_y','17_y','18_y','19_y','20_y','21_y','22_y','23_y','24_y','25_y','26_y','27_y','28_y','29_y','30_y','31_y','32_y','33_y','34_y','35_y','36_y','37_y','38_y','39_y','40_y','41_y','42_y','43_y','44_y','45_y','46_y','47_y','48_y','49_y','50_y','51_y','52_y','53_y','54_y','55_y','56_y','57_y','58_y','59_y','60_y','61_y','62_y','63_y','64_y','65_y','66_y','67_y','68_y','69_y','70_y','71_y','72_y','73_y','74_y','75_y','76_y','77_y','78_y','79_y','80_y','81_y','82_y','83_y','84_y','85_y','86_y','87_y','88_y','89_y','90_y','91_y','92_y','93_y','94_y','95_y','96_y','97_y','98_y','99_y','100_y','101_y','102_y','103_y','104_y','105_y','106_y','107_y','108_y','109_y','110_y','111_y','112_y','113_y','114_y','115_y','116_y','117_y','118_y','119_y','120_y','121_y','122_y','123_y','124_y','125_y','126_y','127_y','128_y','129_y','130_y','131_y','132_y','133_y','134_y','135_y','136_y','137_y','138_y','139_y','140_y','141_y','142_y','143_y','144_y','145_y','146_y','147_y','148_y','149_y','150_y','151_y','152_y','153_y','154_y','155_y','156_y','157_y','158_y','159_y','160_y','161_y','162_y','163_y','164_y','165_y','166_y','167_y','168_y','169_y','170_y','171_y','172_y','173_y','174_y','175_y','176_y','177_y','178_y','179_y','180_y','181_y','182_y','183_y','184_y','185_y','186_y','187_y','188_y','189_y','190_y','191_y','192_y','193_y','194_y','195_y','196_y','197_y','198_y','199_y','200_y','201_y','202_y','203_y','204_y','205_y','206_y','207_y','208_y','209_y','210_y','211_y','212_y','213_y','214_y','215_y','216_y','217_y','218_y','219_y','220_y','221_y','222_y','223_y','224_y','225_y','226_y','227_y','228_y','229_y','230_y','231_y','232_y','233_y','234_y','235_y','236_y','237_y','238_y','239_y','240_y','241_y','242_y','243_y','244_y','245_y','246_y','247_y','248_y','249_y','250_y','251_y','252_y','253_y','254_y','255_y','256_y','257_y','258_y','259_y','260_y','261_y','262_y','263_y','264_y','265_y','266_y','267_y','268_y','269_y','270_y','271_y','272_y','273_y','274_y','275_y','276_y','277_y','278_y','279_y','280_y','281_y','282_y','283_y','284_y','285_y','286_y','287_y','288_y','289_y','290_y','291_y','292_y','293_y','294_y','295_y','296_y','297_y','298_y','299_y','300_y','301_y','302_y','303_y','304_y','305_y','306_y','307_y','308_y','309_y','310_y','311_y','312_y','313_y','314_y','315_y','316_y','317_y','318_y','319_y','320_y','321_y','322_y','323_y','324_y','325_y','326_y','327_y','328_y','329_y','330_y','331_y','332_y','333_y','334_y','335_y','336_y','337_y','338_y','339_y','340_y','341_y','342_y','343_y','344_y','345_y','346_y','347_y','348_y','349_y','350_y','351_y','352_y','353_y','354_y','355_y','356_y','357_y','358_y','359_y','360_y','361_y','362_y','363_y','364_y','365_y','366_y','367_y','368_y','369_y','370_y','371_y','372_y','373_y','374_y','375_y','376_y','377_y','378_y','379_y','380_y','381_y','382_y','383_y'], \n",
    "                          chunksize=chunksize, iterator=True, encoding='utf-8', ):\n",
    "        data.index += index_start\n",
    "        j+=1\n",
    "        print('{} rows'.format(j*chunksize))\n",
    "        data.to_sql('data', disk_engine, if_exists='append')\n",
    "        index_start = data.index[-1] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadc81cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.sqlitetutorial.net/sqlite-python/create-tables/\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    " \n",
    "    return None\n",
    "\n",
    "\n",
    "def checkTableExists(dbcon):\n",
    "    cursr = dbcon.cursor()\n",
    "    str = \"select name from sqlite_master where type='table'\"\n",
    "    table_names = cursr.execute(str)\n",
    "    print(\"Tables in the databse:\")\n",
    "    tables =table_names.fetchall() \n",
    "    print(tables[0][0])\n",
    "    return(len(tables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79563e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in the databse:\n",
      "data\n"
     ]
    }
   ],
   "source": [
    "read_db = 'train.db'\n",
    "conn_r = create_connection(read_db)\n",
    "checkTableExists(conn_r)\n",
    "conn_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc99034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to sample data according to the computing power you have\n",
    "if os.path.isfile(read_db):\n",
    "    conn_r = create_connection(read_db)\n",
    "    if conn_r is not None:\n",
    "        # for selecting first 1M rows\n",
    "        # data = pd.read_sql_query(\"\"\"SELECT * FROM data LIMIT 100001;\"\"\", conn_r)\n",
    "        \n",
    "        # for selecting random points\n",
    "        data = pd.read_sql_query(\"SELECT * From data ORDER BY RANDOM() ;\", conn_r)\n",
    "        conn_r.commit()\n",
    "        conn_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7ba10c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the first row \n",
    "data.drop(data.index[0], inplace=True)\n",
    "y_true = data['is_duplicate']\n",
    "data.drop(['Unnamed: 0','index','is_duplicate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48b2c046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>86_y</th>\n",
       "      <th>87_y</th>\n",
       "      <th>88_y</th>\n",
       "      <th>89_y</th>\n",
       "      <th>90_y</th>\n",
       "      <th>91_y</th>\n",
       "      <th>92_y</th>\n",
       "      <th>93_y</th>\n",
       "      <th>94_y</th>\n",
       "      <th>95_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4630</td>\n",
       "      <td>0.999900009999</td>\n",
       "      <td>0.999900009999</td>\n",
       "      <td>0.199996000079998</td>\n",
       "      <td>0.199996000079998</td>\n",
       "      <td>0.333327777870369</td>\n",
       "      <td>0.285710204139941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.46980580687523</td>\n",
       "      <td>13.559701114893</td>\n",
       "      <td>1.26115715503693</td>\n",
       "      <td>0.987946510314941</td>\n",
       "      <td>-6.54793980717659</td>\n",
       "      <td>26.5230768918991</td>\n",
       "      <td>-2.51610924303532</td>\n",
       "      <td>0.717215843498707</td>\n",
       "      <td>-7.01951596140862</td>\n",
       "      <td>-1.41556656360626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207957</td>\n",
       "      <td>0.749981250468738</td>\n",
       "      <td>0.29999700003</td>\n",
       "      <td>0.499987500312492</td>\n",
       "      <td>0.333327777870369</td>\n",
       "      <td>0.555549382784636</td>\n",
       "      <td>0.294115916965194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.73271518945694</td>\n",
       "      <td>-78.1869869828224</td>\n",
       "      <td>20.0271127820015</td>\n",
       "      <td>5.44644759595394</td>\n",
       "      <td>31.377969621215</td>\n",
       "      <td>76.7795774787664</td>\n",
       "      <td>22.7472011446953</td>\n",
       "      <td>18.711423650384</td>\n",
       "      <td>-27.4625603333116</td>\n",
       "      <td>22.9692741110921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>331746</td>\n",
       "      <td>0.285710204139941</td>\n",
       "      <td>0.222219753113854</td>\n",
       "      <td>0.749981250468738</td>\n",
       "      <td>0.499991666805553</td>\n",
       "      <td>0.384612426058261</td>\n",
       "      <td>0.277776234576475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5760343335569</td>\n",
       "      <td>-36.9434238225222</td>\n",
       "      <td>-23.0053095817566</td>\n",
       "      <td>14.849276676774</td>\n",
       "      <td>-2.0597610771656</td>\n",
       "      <td>10.4770546108484</td>\n",
       "      <td>6.87894546985626</td>\n",
       "      <td>14.8732445240021</td>\n",
       "      <td>-2.51985162496567</td>\n",
       "      <td>1.27595530450344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36791</td>\n",
       "      <td>0.999966667777741</td>\n",
       "      <td>0.599988000239995</td>\n",
       "      <td>0.66664444518516</td>\n",
       "      <td>0.499987500312492</td>\n",
       "      <td>0.833319444675922</td>\n",
       "      <td>0.555549382784636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.8740690052509</td>\n",
       "      <td>-4.34518650174141</td>\n",
       "      <td>0.964694976806641</td>\n",
       "      <td>6.1144837141037</td>\n",
       "      <td>-10.1161348819733</td>\n",
       "      <td>39.763225197792</td>\n",
       "      <td>-6.56559979915619</td>\n",
       "      <td>-13.1160526275635</td>\n",
       "      <td>-17.2573935687542</td>\n",
       "      <td>20.726873729378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>44249</td>\n",
       "      <td>0.999950002499875</td>\n",
       "      <td>0.66664444518516</td>\n",
       "      <td>0.66664444518516</td>\n",
       "      <td>0.499987500312492</td>\n",
       "      <td>0.799984000319994</td>\n",
       "      <td>0.499993750078124</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.4912744760513</td>\n",
       "      <td>8.96269625425339</td>\n",
       "      <td>-20.5269424766302</td>\n",
       "      <td>0.325389802455902</td>\n",
       "      <td>-25.7694354057312</td>\n",
       "      <td>5.10899311304092</td>\n",
       "      <td>6.66325527429581</td>\n",
       "      <td>15.7665190547705</td>\n",
       "      <td>7.50827720761299</td>\n",
       "      <td>19.0291977822781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 219 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id            cwc_min            cwc_max            csc_min  \\\n",
       "1    4630     0.999900009999     0.999900009999  0.199996000079998   \n",
       "2  207957  0.749981250468738      0.29999700003  0.499987500312492   \n",
       "3  331746  0.285710204139941  0.222219753113854  0.749981250468738   \n",
       "4   36791  0.999966667777741  0.599988000239995   0.66664444518516   \n",
       "5   44249  0.999950002499875   0.66664444518516   0.66664444518516   \n",
       "\n",
       "             csc_max            ctc_min            ctc_max last_word_eq  \\\n",
       "1  0.199996000079998  0.333327777870369  0.285710204139941          0.0   \n",
       "2  0.333327777870369  0.555549382784636  0.294115916965194          0.0   \n",
       "3  0.499991666805553  0.384612426058261  0.277776234576475          0.0   \n",
       "4  0.499987500312492  0.833319444675922  0.555549382784636          1.0   \n",
       "5  0.499987500312492  0.799984000319994  0.499993750078124          1.0   \n",
       "\n",
       "  first_word_eq abs_len_diff  ...              86_y               87_y  \\\n",
       "1           0.0          1.0  ...  4.46980580687523    13.559701114893   \n",
       "2           0.0          8.0  ...  4.73271518945694  -78.1869869828224   \n",
       "3           1.0          5.0  ...  17.5760343335569  -36.9434238225222   \n",
       "4           0.0          3.0  ...  13.8740690052509  -4.34518650174141   \n",
       "5           0.0          3.0  ...  16.4912744760513   8.96269625425339   \n",
       "\n",
       "                88_y               89_y               90_y              91_y  \\\n",
       "1   1.26115715503693  0.987946510314941  -6.54793980717659  26.5230768918991   \n",
       "2   20.0271127820015   5.44644759595394    31.377969621215  76.7795774787664   \n",
       "3  -23.0053095817566    14.849276676774   -2.0597610771656  10.4770546108484   \n",
       "4  0.964694976806641    6.1144837141037  -10.1161348819733   39.763225197792   \n",
       "5  -20.5269424766302  0.325389802455902  -25.7694354057312  5.10899311304092   \n",
       "\n",
       "                92_y               93_y               94_y               95_y  \n",
       "1  -2.51610924303532  0.717215843498707  -7.01951596140862  -1.41556656360626  \n",
       "2   22.7472011446953    18.711423650384  -27.4625603333116   22.9692741110921  \n",
       "3   6.87894546985626   14.8732445240021  -2.51985162496567   1.27595530450344  \n",
       "4  -6.56559979915619  -13.1160526275635  -17.2573935687542    20.726873729378  \n",
       "5   6.66325527429581   15.7665190547705   7.50827720761299   19.0291977822781  \n",
       "\n",
       "[5 rows x 219 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6a06be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of             id            cwc_min            cwc_max            csc_min  \\\n",
       "1         4630     0.999900009999     0.999900009999  0.199996000079998   \n",
       "2       207957  0.749981250468738      0.29999700003  0.499987500312492   \n",
       "3       331746  0.285710204139941  0.222219753113854  0.749981250468738   \n",
       "4        36791  0.999966667777741  0.599988000239995   0.66664444518516   \n",
       "5        44249  0.999950002499875   0.66664444518516   0.66664444518516   \n",
       "...        ...                ...                ...                ...   \n",
       "404286   70734  0.499975001249937   0.33332222259258     0.999900009999   \n",
       "404287  226799  0.749981250468738  0.749981250468738  0.999975000624984   \n",
       "404288  181545  0.999966667777741  0.749981250468738  0.499975001249937   \n",
       "404289  226901  0.999966667777741  0.749981250468738  0.999950002499875   \n",
       "404290  367976                0.0                0.0  0.199996000079998   \n",
       "\n",
       "                  csc_max            ctc_min             ctc_max last_word_eq  \\\n",
       "1       0.199996000079998  0.333327777870369   0.285710204139941          0.0   \n",
       "2       0.333327777870369  0.555549382784636   0.294115916965194          0.0   \n",
       "3       0.499991666805553  0.384612426058261   0.277776234576475          0.0   \n",
       "4       0.499987500312492  0.833319444675922   0.555549382784636          1.0   \n",
       "5       0.499987500312492  0.799984000319994   0.499993750078124          1.0   \n",
       "...                   ...                ...                 ...          ...   \n",
       "404286     0.999900009999   0.66664444518516   0.499987500312492          1.0   \n",
       "404287  0.999975000624984  0.874989062636717   0.874989062636717          1.0   \n",
       "404288   0.33332222259258  0.666655555740738   0.666655555740738          1.0   \n",
       "404289  0.999950002499875  0.999980000399992   0.833319444675922          1.0   \n",
       "404290  0.199996000079998  0.111109876556927  0.0999990000099999          0.0   \n",
       "\n",
       "       first_word_eq abs_len_diff  ...               86_y                87_y  \\\n",
       "1                0.0          1.0  ...   4.46980580687523     13.559701114893   \n",
       "2                0.0          8.0  ...   4.73271518945694   -78.1869869828224   \n",
       "3                1.0          5.0  ...   17.5760343335569   -36.9434238225222   \n",
       "4                0.0          3.0  ...   13.8740690052509   -4.34518650174141   \n",
       "5                0.0          3.0  ...   16.4912744760513    8.96269625425339   \n",
       "...              ...          ...  ...                ...                 ...   \n",
       "404286           1.0          1.0  ...   13.1179105043411    4.83427882194519   \n",
       "404287           1.0          0.0  ...  -4.14532896876335  -0.173733860254288   \n",
       "404288           1.0          0.0  ...  -2.88472920656204    5.00245875120163   \n",
       "404289           1.0          1.0  ...   24.7499587535858   -19.2496984004974   \n",
       "404290           0.0          1.0  ...   2.85872875154018   -4.95254135131836   \n",
       "\n",
       "                      88_y               89_y               90_y  \\\n",
       "1         1.26115715503693  0.987946510314941  -6.54793980717659   \n",
       "2         20.0271127820015   5.44644759595394    31.377969621215   \n",
       "3        -23.0053095817566    14.849276676774   -2.0597610771656   \n",
       "4        0.964694976806641    6.1144837141037  -10.1161348819733   \n",
       "5        -20.5269424766302  0.325389802455902  -25.7694354057312   \n",
       "...                    ...                ...                ...   \n",
       "404286   -28.7172734737396   16.9173939228058  0.407730728387833   \n",
       "404287  0.0215284824371337   -12.466347694397   13.6064549088478   \n",
       "404288   -15.8094578683376   10.4314998090267  -21.9985131025314   \n",
       "404289   -35.0258768498898  -23.5032361745834  -38.9422298371792   \n",
       "404290   -25.2857683449984   20.1806678771973  -30.9745125025511   \n",
       "\n",
       "                     91_y               92_y               93_y  \\\n",
       "1        26.5230768918991  -2.51610924303532  0.717215843498707   \n",
       "2        76.7795774787664   22.7472011446953    18.711423650384   \n",
       "3        10.4770546108484   6.87894546985626   14.8732445240021   \n",
       "4         39.763225197792  -6.56559979915619  -13.1160526275635   \n",
       "5        5.10899311304092   6.66325527429581   15.7665190547705   \n",
       "...                   ...                ...                ...   \n",
       "404286   7.49470746517181   23.7114036083221   9.30392575263977   \n",
       "404287   9.92314402759075   33.4400770068169   17.4916376471519   \n",
       "404288  -2.01280642300844   5.49666577577591   16.3832110613585   \n",
       "404289  -16.3066410124302    37.303417801857   36.3410497903824   \n",
       "404290   16.5954744517803  0.492766261100769   8.70045945420861   \n",
       "\n",
       "                     94_y               95_y  \n",
       "1       -7.01951596140862  -1.41556656360626  \n",
       "2       -27.4625603333116   22.9692741110921  \n",
       "3       -2.51985162496567   1.27595530450344  \n",
       "4       -17.2573935687542    20.726873729378  \n",
       "5        7.50827720761299   19.0291977822781  \n",
       "...                   ...                ...  \n",
       "404286  -7.58918619155884   14.0626448392868  \n",
       "404287   -22.874981701374     3.454794049263  \n",
       "404288   15.6557418107986    9.8357703089714  \n",
       "404289   1.82969260215759  -12.9029442965984  \n",
       "404290   17.8471455648541  -4.22317457199097  \n",
       "\n",
       "[404290 rows x 219 columns]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b07ac",
   "metadata": {},
   "source": [
    "## 4.2 Converting Strings to Numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12918b6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "cwc_min\n",
      "cwc_max\n",
      "csc_min\n",
      "csc_max\n",
      "ctc_min\n",
      "ctc_max\n",
      "last_word_eq\n",
      "first_word_eq\n",
      "abs_len_diff\n",
      "mean_len\n",
      "token_set_ratio\n",
      "token_sort_ratio\n",
      "fuzz_ratio\n",
      "fuzz_partial_ratio\n",
      "longest_substr_ratio\n",
      "freq_qid1\n",
      "freq_qid2\n",
      "q1len\n",
      "q2len\n",
      "q1_n_words\n",
      "q2_n_words\n",
      "word_Common\n",
      "word_Total\n",
      "word_share\n",
      "freq_q1+q2\n",
      "freq_q1-q2\n",
      "0_x\n",
      "1_x\n",
      "2_x\n",
      "3_x\n",
      "4_x\n",
      "5_x\n",
      "6_x\n",
      "7_x\n",
      "8_x\n",
      "9_x\n",
      "10_x\n",
      "11_x\n",
      "12_x\n",
      "13_x\n",
      "14_x\n",
      "15_x\n",
      "16_x\n",
      "17_x\n",
      "18_x\n",
      "19_x\n",
      "20_x\n",
      "21_x\n",
      "22_x\n",
      "23_x\n",
      "24_x\n",
      "25_x\n",
      "26_x\n",
      "27_x\n",
      "28_x\n",
      "29_x\n",
      "30_x\n",
      "31_x\n",
      "32_x\n",
      "33_x\n",
      "34_x\n",
      "35_x\n",
      "36_x\n",
      "37_x\n",
      "38_x\n",
      "39_x\n",
      "40_x\n",
      "41_x\n",
      "42_x\n",
      "43_x\n",
      "44_x\n",
      "45_x\n",
      "46_x\n",
      "47_x\n",
      "48_x\n",
      "49_x\n",
      "50_x\n",
      "51_x\n",
      "52_x\n",
      "53_x\n",
      "54_x\n",
      "55_x\n",
      "56_x\n",
      "57_x\n",
      "58_x\n",
      "59_x\n",
      "60_x\n",
      "61_x\n",
      "62_x\n",
      "63_x\n",
      "64_x\n",
      "65_x\n",
      "66_x\n",
      "67_x\n",
      "68_x\n",
      "69_x\n",
      "70_x\n",
      "71_x\n",
      "72_x\n",
      "73_x\n",
      "74_x\n",
      "75_x\n",
      "76_x\n",
      "77_x\n",
      "78_x\n",
      "79_x\n",
      "80_x\n",
      "81_x\n",
      "82_x\n",
      "83_x\n",
      "84_x\n",
      "85_x\n",
      "86_x\n",
      "87_x\n",
      "88_x\n",
      "89_x\n",
      "90_x\n",
      "91_x\n",
      "92_x\n",
      "93_x\n",
      "94_x\n",
      "95_x\n",
      "0_y\n",
      "1_y\n",
      "2_y\n",
      "3_y\n",
      "4_y\n",
      "5_y\n",
      "6_y\n",
      "7_y\n",
      "8_y\n",
      "9_y\n",
      "10_y\n",
      "11_y\n",
      "12_y\n",
      "13_y\n",
      "14_y\n",
      "15_y\n",
      "16_y\n",
      "17_y\n",
      "18_y\n",
      "19_y\n",
      "20_y\n",
      "21_y\n",
      "22_y\n",
      "23_y\n",
      "24_y\n",
      "25_y\n",
      "26_y\n",
      "27_y\n",
      "28_y\n",
      "29_y\n",
      "30_y\n",
      "31_y\n",
      "32_y\n",
      "33_y\n",
      "34_y\n",
      "35_y\n",
      "36_y\n",
      "37_y\n",
      "38_y\n",
      "39_y\n",
      "40_y\n",
      "41_y\n",
      "42_y\n",
      "43_y\n",
      "44_y\n",
      "45_y\n",
      "46_y\n",
      "47_y\n",
      "48_y\n",
      "49_y\n",
      "50_y\n",
      "51_y\n",
      "52_y\n",
      "53_y\n",
      "54_y\n",
      "55_y\n",
      "56_y\n",
      "57_y\n",
      "58_y\n",
      "59_y\n",
      "60_y\n",
      "61_y\n",
      "62_y\n",
      "63_y\n",
      "64_y\n",
      "65_y\n",
      "66_y\n",
      "67_y\n",
      "68_y\n",
      "69_y\n",
      "70_y\n",
      "71_y\n",
      "72_y\n",
      "73_y\n",
      "74_y\n",
      "75_y\n",
      "76_y\n",
      "77_y\n",
      "78_y\n",
      "79_y\n",
      "80_y\n",
      "81_y\n",
      "82_y\n",
      "83_y\n",
      "84_y\n",
      "85_y\n",
      "86_y\n",
      "87_y\n",
      "88_y\n",
      "89_y\n",
      "90_y\n",
      "91_y\n",
      "92_y\n",
      "93_y\n",
      "94_y\n",
      "95_y\n"
     ]
    }
   ],
   "source": [
    "# after we read from sql table each entry was read it as a string\n",
    "# we convert all the features into numeric before we apply any model\n",
    "cols = list(data.columns)\n",
    "for i in cols:\n",
    "    data[i] = data[i].apply(pd.to_numeric)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b03a277e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/7368789/convert-all-strings-in-a-list-to-int\n",
    "y_true = list(map(int, y_true.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18fe9d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of             id   cwc_min   cwc_max   csc_min   csc_max   ctc_min   ctc_max  \\\n",
       "1       256414  0.666656  0.307690  0.749981  0.333330  0.583328  0.259258   \n",
       "2        20398  0.999967  0.999967  0.499975  0.333322  0.799984  0.666656   \n",
       "3       133898  0.000000  0.000000  0.428565  0.333330  0.124999  0.124999   \n",
       "4       245746  0.666644  0.499988  0.000000  0.000000  0.333328  0.249997   \n",
       "5        82538  0.399992  0.285710  0.333322  0.249994  0.374995  0.272725   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "249996  166090  0.000000  0.000000  0.249994  0.142855  0.111110  0.083333   \n",
       "249997   83565  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "249998  185851  0.499992  0.499992  0.749981  0.749981  0.599994  0.599994   \n",
       "249999  129768  0.333322  0.142855  0.249994  0.166664  0.285710  0.142856   \n",
       "250000   25667  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        last_word_eq  first_word_eq  abs_len_diff  ...       86_y       87_y  \\\n",
       "1                0.0            0.0          15.0  ... -21.947161   6.082530   \n",
       "2                0.0            0.0           1.0  ...  18.904996 -15.618511   \n",
       "3                0.0            0.0           0.0  ...  41.757771 -41.574058   \n",
       "4                1.0            0.0           2.0  ...  -5.529771   8.567686   \n",
       "5                0.0            1.0           3.0  ...  28.358986 -19.376370   \n",
       "...              ...            ...           ...  ...        ...        ...   \n",
       "249996           0.0            0.0           3.0  ... -22.099564 -20.466346   \n",
       "249997           0.0            0.0           3.0  ...  -4.835090  -5.378248   \n",
       "249998           0.0            1.0           0.0  ...   8.675091  -0.103369   \n",
       "249999           0.0            0.0           7.0  ...  15.023591 -39.023808   \n",
       "250000           0.0            0.0           6.0  ...  -0.901644   1.735038   \n",
       "\n",
       "             88_y       89_y       90_y       91_y       92_y       93_y  \\\n",
       "1      -36.182914  14.356363 -47.705078  18.895907 -18.818638  32.292462   \n",
       "2      -16.329942 -12.410466 -17.752307   2.595937   1.543220  32.422797   \n",
       "3      -39.386695  24.007897 -24.200902  41.828114  38.143382  90.577964   \n",
       "4      -29.530925 -15.733860 -17.606457   4.980018   8.950795  13.175325   \n",
       "5      -36.553600   5.691886 -35.197919  -4.302634  39.571533  24.355364   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "249996 -14.721072   5.823814   7.725697  32.926160  22.222643   0.307239   \n",
       "249997  -2.736986   1.790358  -9.762458  50.059095  -8.368041  -2.042696   \n",
       "249998 -21.193100  30.763015 -30.479872  -4.446131   9.038666  10.057855   \n",
       "249999 -38.223702  23.455314 -20.772778  20.055352  18.704884  16.982125   \n",
       "250000  -1.532083  39.707177 -18.525060  53.276687   3.335204  25.615508   \n",
       "\n",
       "             94_y       95_y  \n",
       "1       20.527630   5.331123  \n",
       "2        6.149624 -11.034273  \n",
       "3       23.324943  -8.865920  \n",
       "4       -2.905916 -10.117345  \n",
       "5       17.353860   5.511190  \n",
       "...           ...        ...  \n",
       "249996 -19.331330  -7.988344  \n",
       "249997   9.422498   8.542182  \n",
       "249998  -0.908194  -6.731272  \n",
       "249999  21.464378 -20.533269  \n",
       "250000   9.661847   8.780548  \n",
       "\n",
       "[250000 rows x 219 columns]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5abf6",
   "metadata": {},
   "source": [
    "## 4.3 Random Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86864427",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, y_true, stratify=y_true, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3dc4726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in training data: (175000, 219)\n",
      "Number of data points in testing data: (75000, 219)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of data points in training data: {X_train.shape}\")\n",
    "print(f\"Number of data points in testing data: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e7ef195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Distribution of output variable in training data  ----------\n",
      "Class 0:  0.6300628571428571 Class 1:  0.36993714285714285\n",
      "---------- Distribution of output variable in testing data  ----------\n",
      "Class 0:  0.6300666666666667 Class 1:  0.36993333333333334\n"
     ]
    }
   ],
   "source": [
    "print(\"-\"*10, \"Distribution of output variable in training data \", \"-\"*10)\n",
    "train_distribution = Counter(y_train)\n",
    "train_length = len(y_train)\n",
    "print(\"Class 0: \", int(train_distribution[0])/train_length, \"Class 1: \", int(train_distribution[1])/train_length)\n",
    "\n",
    "print(\"-\"*10, \"Distribution of output variable in testing data \", \"-\"*10)\n",
    "test_distribution = Counter(y_test)\n",
    "test_length = len(y_test)\n",
    "print(\"Class 0: \", int(test_distribution[0])/test_length, \"Class 1: \", int(test_distribution[1])/test_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e04c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(test_y, predict_y):\n",
    "    C = confusion_matrix(test_y, predict_y)\n",
    "    # C = 9,9 matrix, each cell (i,j) represents number of points of class i are predicted class j\n",
    "    \n",
    "    A =(((C.T)/(C.sum(axis=1))).T)\n",
    "    #divid each element of the confusion matrix with the sum of elements in that column\n",
    "    \n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.T = [[1, 3],\n",
    "    #        [2, 4]]\n",
    "    # C.sum(axis = 1)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =1) = [[3, 7]]\n",
    "    # ((C.T)/(C.sum(axis=1))) = [[1/3, 3/7]\n",
    "    #                           [2/3, 4/7]]\n",
    "\n",
    "    # ((C.T)/(C.sum(axis=1))).T = [[1/3, 2/3]\n",
    "    #                           [3/7, 4/7]]\n",
    "    # sum of row elements = 1\n",
    "    \n",
    "    B =(C/C.sum(axis=0))\n",
    "    #divid each element of the confusion matrix with the sum of elements in that row\n",
    "    # C = [[1, 2],\n",
    "    #     [3, 4]]\n",
    "    # C.sum(axis = 0)  axis=0 corresonds to columns and axis=1 corresponds to rows in two diamensional array\n",
    "    # C.sum(axix =0) = [[4, 6]]\n",
    "    # (C/C.sum(axis=0)) = [[1/4, 2/6],\n",
    "    #                      [3/4, 4/6]] \n",
    "    plt.figure(figsize=(20,4))\n",
    "    \n",
    "    labels = [1,2]\n",
    "    # representing A in heatmap format\n",
    "    cmap=sns.light_palette(\"blue\")\n",
    "    plt.subplot(1, 3, 1)\n",
    "    sns.heatmap(C, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    sns.heatmap(B, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Precision matrix\")\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    # representing B in heatmap format\n",
    "    sns.heatmap(A, annot=True, cmap=cmap, fmt=\".3f\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel('Predicted Class')\n",
    "    plt.ylabel('Original Class')\n",
    "    plt.title(\"Recall matrix\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0807522d",
   "metadata": {},
   "source": [
    "## 4.4 Building a Random model (Finding the worst log-loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab0988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to generate 9 numbers and the sum of numbers should be 1\n",
    "# one solution is to genarate 9 numbers and divide each of the numbers by their sum\n",
    "# ref: https://stackoverflow.com/a/18662466/4084039\n",
    "# we create a output array that has exactly same size as the CV data\n",
    "\n",
    "predicted_y = np.zeros((test_length, 2))\n",
    "\n",
    "for i in range(test_length):\n",
    "    rand_probs = np.random.rand(1,2)\n",
    "    predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\n",
    "    \n",
    "print(\"Log loss on test data using a Random Model: \", log_loss(y_test, predicted_y, eps = 1e-15))\n",
    "\n",
    "predicted_y = np.argmax(predicted_y, axis = 1)\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e77bc8",
   "metadata": {},
   "source": [
    "## 4.5 Logistic Regression with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf978c09",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7104b76efb4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msig_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCalibratedClassifierCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0msig_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mpredict_y\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0msig_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mlog_error_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    309\u001b[0m                 \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m                 self.calibrated_classifiers_ = parallel(\n\u001b[0m\u001b[0;32m    312\u001b[0m                     delayed(_fit_classifier_calibrator_pair)(\n\u001b[0;32m    313\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py\u001b[0m in \u001b[0;36m_fit_classifier_calibrator_pair\u001b[1;34m(estimator, X, y, train, test, supports_sw, method, classes, sample_weight)\u001b[0m\n\u001b[0;32m    439\u001b[0m                       sample_weight=sample_weight[train])\n\u001b[0;32m    440\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[0mn_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m         \"\"\"\n\u001b[1;32m--> 729\u001b[1;33m         return self._fit(X, y, alpha=self.alpha, C=1.0,\n\u001b[0m\u001b[0;32m    730\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self.max_iter,\n\u001b[0m\u001b[0;32m    570\u001b[0m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[0;32m    524\u001b[0m                                  max_iter=max_iter)\n\u001b[0;32m    525\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mn_classes\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 526\u001b[1;33m             self._fit_binary(X, y, alpha=alpha, C=C,\n\u001b[0m\u001b[0;32m    527\u001b[0m                              \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m                              \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[1;34m(self, X, y, alpha, C, sample_weight, learning_rate, max_iter)\u001b[0m\n\u001b[0;32m    581\u001b[0m                     learning_rate, max_iter):\n\u001b[0;32m    582\u001b[0m         \u001b[1;34m\"\"\"Fit a binary classifier on X and y. \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m         coef, intercept, n_iter_ = fit_binary(self, 1, X, y, alpha, C,\n\u001b[0m\u001b[0;32m    584\u001b[0m                                               \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_expanded_class_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit_binary\u001b[1;34m(est, i, X, y, alpha, C, learning_rate, max_iter, pos_weight, neg_weight, sample_weight, validation_mask, random_state)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \u001b[0mtol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m     coef, intercept, average_coef, average_intercept, n_iter_ = _plain_sgd(\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[0mcoef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage_intercept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_function_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[0mpenalty_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha = [10 ** x for x in range(-5, 2)]\n",
    "\n",
    "log_error_array = []\n",
    "for i in alpha:\n",
    "    classifier = SGDClassifier(alpha = i, penalty = 'l2', loss = 'log', random_state = 42)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    sig_classifier = CalibratedClassifierCV(classifier, method='sigmoid')\n",
    "    sig_classifier.fit(X_train, y_train)\n",
    "    predict_y =sig_classifier.predict_proba(X_test)\n",
    "    log_error_array.append(log_loss(y_test, predict_y, labels=classifier.classes_, eps=1e-15))\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array, c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array, 3)):\n",
    "        ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(alpha, log_error_array,c='g')\n",
    "for i, txt in enumerate(np.round(log_error_array,3)):\n",
    "    ax.annotate((alpha[i],np.round(txt,3)), (alpha[i],log_error_array[i]))\n",
    "plt.grid()\n",
    "plt.title(\"Cross Validation Error for each alpha\")\n",
    "plt.xlabel(\"Alpha i's\")\n",
    "plt.ylabel(\"Error measure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b4da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha = np.argmin(log_error_array)\n",
    "classifier = SGDClassifier(alpha=alpha[best_alpha], penalty='l1', loss='hinge', random_state=42)\n",
    "classifier.fit(X_train, y_train)\n",
    "sig_classifier = CalibratedClassifierCV(classifier, method=\"sigmoid\")\n",
    "sig_classifier.fit(X_train, y_train)\n",
    "\n",
    "predict_y = sig_classifier.predict_proba(X_train)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The train log loss is:\",log_loss(y_train, predict_y, labels=classifier.classes_, eps=1e-15))\n",
    "predict_y = sig_classifier.predict_proba(X_test)\n",
    "print('For values of best alpha = ', alpha[best_alpha], \"The test log loss is:\",log_loss(y_test, predict_y, labels=classifier.classes_, eps=1e-15))\n",
    "predicted_y =np.argmax(predict_y,axis=1)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba2e768",
   "metadata": {},
   "source": [
    "## 4.6 XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7239fa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68471\tvalid-logloss:0.68464\n",
      "[10]\ttrain-logloss:0.61477\tvalid-logloss:0.61467\n",
      "[20]\ttrain-logloss:0.56429\tvalid-logloss:0.56408\n",
      "[30]\ttrain-logloss:0.52653\tvalid-logloss:0.52628\n",
      "[40]\ttrain-logloss:0.49727\tvalid-logloss:0.49696\n",
      "[50]\ttrain-logloss:0.47428\tvalid-logloss:0.47396\n",
      "[60]\ttrain-logloss:0.45601\tvalid-logloss:0.45571\n",
      "[70]\ttrain-logloss:0.44143\tvalid-logloss:0.44120\n",
      "[80]\ttrain-logloss:0.42956\tvalid-logloss:0.42934\n",
      "[90]\ttrain-logloss:0.41983\tvalid-logloss:0.41967\n",
      "[100]\ttrain-logloss:0.41185\tvalid-logloss:0.41177\n",
      "[110]\ttrain-logloss:0.40522\tvalid-logloss:0.40522\n",
      "[120]\ttrain-logloss:0.39967\tvalid-logloss:0.39973\n",
      "[130]\ttrain-logloss:0.39498\tvalid-logloss:0.39508\n",
      "[140]\ttrain-logloss:0.39110\tvalid-logloss:0.39130\n",
      "[150]\ttrain-logloss:0.38772\tvalid-logloss:0.38805\n",
      "[160]\ttrain-logloss:0.38482\tvalid-logloss:0.38526\n",
      "[170]\ttrain-logloss:0.38213\tvalid-logloss:0.38266\n",
      "[180]\ttrain-logloss:0.37961\tvalid-logloss:0.38019\n",
      "[190]\ttrain-logloss:0.37743\tvalid-logloss:0.37807\n",
      "[200]\ttrain-logloss:0.37523\tvalid-logloss:0.37594\n",
      "[210]\ttrain-logloss:0.37334\tvalid-logloss:0.37412\n",
      "[220]\ttrain-logloss:0.37150\tvalid-logloss:0.37238\n",
      "[230]\ttrain-logloss:0.36982\tvalid-logloss:0.37076\n",
      "[240]\ttrain-logloss:0.36821\tvalid-logloss:0.36925\n",
      "[250]\ttrain-logloss:0.36663\tvalid-logloss:0.36775\n",
      "[260]\ttrain-logloss:0.36492\tvalid-logloss:0.36610\n",
      "[270]\ttrain-logloss:0.36355\tvalid-logloss:0.36483\n",
      "[280]\ttrain-logloss:0.36229\tvalid-logloss:0.36365\n",
      "[290]\ttrain-logloss:0.36121\tvalid-logloss:0.36266\n",
      "[300]\ttrain-logloss:0.36017\tvalid-logloss:0.36172\n",
      "[310]\ttrain-logloss:0.35909\tvalid-logloss:0.36077\n",
      "[320]\ttrain-logloss:0.35810\tvalid-logloss:0.35988\n",
      "[330]\ttrain-logloss:0.35719\tvalid-logloss:0.35908\n",
      "[340]\ttrain-logloss:0.35631\tvalid-logloss:0.35828\n",
      "[350]\ttrain-logloss:0.35538\tvalid-logloss:0.35744\n",
      "[360]\ttrain-logloss:0.35445\tvalid-logloss:0.35660\n",
      "[370]\ttrain-logloss:0.35357\tvalid-logloss:0.35581\n",
      "[380]\ttrain-logloss:0.35268\tvalid-logloss:0.35502\n",
      "[390]\ttrain-logloss:0.35179\tvalid-logloss:0.35424\n",
      "[399]\ttrain-logloss:0.35102\tvalid-logloss:0.35357\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6a716386aea2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mxgdmat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mpredict_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The test log loss is:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eval_metric'] = 'logloss'\n",
    "params['eta'] = 0.02\n",
    "params['max_depth'] = 4\n",
    "\n",
    "d_train = xgb.DMatrix(X_train, label=y_train)\n",
    "d_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "watchlist = [(d_train, 'train'), (d_test, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 400, watchlist, early_stopping_rounds=20, verbose_eval=10)\n",
    "\n",
    "xgdmat = xgb.DMatrix(X_train,y_train)\n",
    "predict_y = bst.predict(d_test)\n",
    "print(\"The test log loss is:\",log_loss(y_test, predict_y, labels=classifier.classes_, eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y =np.array(predict_y>0.5,dtype=int)\n",
    "print(\"Total number of data points :\", len(predicted_y))\n",
    "plot_confusion_matrix(y_test, predicted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78a8b2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_test = xgb.DMatrix(X_test, label=y_test)\n",
    "predict_y = bst.predict(d_test)\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['test_id'] = X_test['id']\n",
    "sub['is_duplicate'] = predict_y\n",
    "sub.to_csv('simple_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e228d9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff59e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
